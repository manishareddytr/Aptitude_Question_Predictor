{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvtCase(s):\n",
    "    return s.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/charishmaambati/Desktop/Cherry/Me/Elite/Dataset4E.csv',sep=',', converters={'Question': cvtCase})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topicQuestion(label):\n",
    "    return data.loc[(data[\"Topic\"] == label),[\"Question\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(sentence):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    filtered_words = [word for word in tokens]\n",
    "    return (\" \".join(filtered_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessedSampleQuestions(label):\n",
    "    return [process(item) for item in topicQuestion(label)[\"Question\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addAllTextSentence(label):\n",
    "    strData  = \" \"\n",
    "    for i in range(len((preprocessedSampleQuestions(label)))):\n",
    "        strData = strData + (((preprocessedSampleQuestions(label))[i]).lower())+ \" \"\n",
    "    return strData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remTksReSentence(label):\n",
    "    remRegExp = re.sub(r'[^\\w]',' ',addAllTextSentence(label))\n",
    "    tokens = remRegExp.split()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessedSampleQuestions(label):\n",
    "    return [process(item) for item in topicQuestion(label)[\"Question\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(set(data[\"Topic\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfTksReWords = [remTksReSentence(label) for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reCommonWords = [process(item) for item in data[\"Question\"] if item not in listOfTksReWords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "test_size 0.1\n",
      "0.9166666666666666\n",
      "test_size 0.2\n",
      "0.90625\n",
      "test_size 0.3\n",
      "0.8928571428571429\n",
      "epoch: 2\n",
      "test_size 0.1\n",
      "0.9166666666666666\n",
      "test_size 0.2\n",
      "0.90625\n",
      "test_size 0.3\n",
      "0.8928571428571429\n",
      "epoch: 3\n",
      "test_size 0.1\n",
      "0.9166666666666666\n",
      "test_size 0.2\n",
      "0.90625\n",
      "test_size 0.3\n",
      "0.8928571428571429\n",
      "epoch: 4\n",
      "test_size 0.1\n",
      "0.9166666666666666\n",
      "test_size 0.2\n",
      "0.90625\n",
      "test_size 0.3\n",
      "0.8928571428571429\n",
      "epoch: 5\n",
      "test_size 0.1\n",
      "0.9166666666666666\n",
      "test_size 0.2\n",
      "0.90625\n",
      "test_size 0.3\n",
      "0.8928571428571429\n",
      "epoch: 6\n",
      "test_size 0.1\n",
      "0.9166666666666666\n",
      "test_size 0.2\n",
      "0.90625\n",
      "test_size 0.3\n",
      "0.8928571428571429\n",
      "epoch: 7\n",
      "test_size 0.1\n",
      "0.9166666666666666\n",
      "test_size 0.2\n",
      "0.90625\n",
      "test_size 0.3\n",
      "0.8928571428571429\n",
      "epoch: 8\n",
      "test_size 0.1\n",
      "0.9166666666666666\n",
      "test_size 0.2\n",
      "0.90625\n",
      "test_size 0.3\n",
      "0.8928571428571429\n",
      "epoch: 9\n",
      "test_size 0.1\n",
      "0.9166666666666666\n",
      "test_size 0.2\n",
      "0.90625\n",
      "test_size 0.3\n",
      "0.8928571428571429\n",
      "epoch: 10\n",
      "test_size 0.1\n",
      "0.9166666666666666\n",
      "test_size 0.2\n",
      "0.90625\n",
      "test_size 0.3\n",
      "0.8928571428571429\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "test_accuracy1 = []\n",
    "val_accuracy1 = []\n",
    "test_split = [0.1,0.2,0.3]\n",
    "for epoch in range(epochs):\n",
    "    print(\"epoch:\", epoch+1)\n",
    "    test_split = [0.1,0.2,0.3]\n",
    "    for i in test_split:\n",
    "        print(\"test_size\", i)\n",
    "        # Spliting the data into train,test and validation in 60 , 20, 20 respectively\n",
    "        Q_train, Q_test, T_train, T_test = train_test_split(reCommonWords,data[\"Topic\"] , test_size=i, random_state=2)\n",
    "        Q_train, Q_val, T_train, T_val  = train_test_split(Q_train, T_train, test_size=0.2, random_state=2)\n",
    "        ## Applying vectorizer\n",
    "        vectorizer = CountVectorizer()\n",
    "        vectorizedTrainQuestions = vectorizer.fit_transform(Q_train)\n",
    "        encodedTestQuestions = vectorizer.transform(Q_test)\n",
    "        valTestQuestions = vectorizer.transform(Q_val)\n",
    "        # Applying multinomialNB\n",
    "        mnb = MultinomialNB()\n",
    "        # Fitting the data\n",
    "        mnb.fit(vectorizedTrainQuestions,T_train)\n",
    "        # Prediction using test data\n",
    "        T_prediction = mnb.predict(encodedTestQuestions)\n",
    "        # Prediction using validation data\n",
    "        val_prediction = mnb.predict(valTestQuestions)\n",
    "        if(i == 0.2):\n",
    "            test_accuracy1.append(accuracy_score(T_prediction,T_test))\n",
    "        val_accuracy1.append(accuracy_score(val_prediction,T_val))\n",
    "        print(accuracy_score(T_val, val_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "test_size 0.1\n",
      "0.9045454545454545\n",
      "test_size 0.2\n",
      "0.9181818181818182\n",
      "test_size 0.3\n",
      "0.9287878787878788\n",
      "epoch: 2\n",
      "test_size 0.1\n",
      "0.9045454545454545\n",
      "test_size 0.2\n",
      "0.9181818181818182\n",
      "test_size 0.3\n",
      "0.9287878787878788\n",
      "epoch: 3\n",
      "test_size 0.1\n",
      "0.9045454545454545\n",
      "test_size 0.2\n",
      "0.9181818181818182\n",
      "test_size 0.3\n",
      "0.9287878787878788\n",
      "epoch: 4\n",
      "test_size 0.1\n",
      "0.9045454545454545\n",
      "test_size 0.2\n",
      "0.9181818181818182\n",
      "test_size 0.3\n",
      "0.9287878787878788\n",
      "epoch: 5\n",
      "test_size 0.1\n",
      "0.9045454545454545\n",
      "test_size 0.2\n",
      "0.9181818181818182\n",
      "test_size 0.3\n",
      "0.9287878787878788\n",
      "epoch: 6\n",
      "test_size 0.1\n",
      "0.9045454545454545\n",
      "test_size 0.2\n",
      "0.9181818181818182\n",
      "test_size 0.3\n",
      "0.9287878787878788\n",
      "epoch: 7\n",
      "test_size 0.1\n",
      "0.9045454545454545\n",
      "test_size 0.2\n",
      "0.9181818181818182\n",
      "test_size 0.3\n",
      "0.9287878787878788\n",
      "epoch: 8\n",
      "test_size 0.1\n",
      "0.9045454545454545\n",
      "test_size 0.2\n",
      "0.9181818181818182\n",
      "test_size 0.3\n",
      "0.9287878787878788\n",
      "epoch: 9\n",
      "test_size 0.1\n",
      "0.9045454545454545\n",
      "test_size 0.2\n",
      "0.9181818181818182\n",
      "test_size 0.3\n",
      "0.9287878787878788\n",
      "epoch: 10\n",
      "test_size 0.1\n",
      "0.9045454545454545\n",
      "test_size 0.2\n",
      "0.9181818181818182\n",
      "test_size 0.3\n",
      "0.9287878787878788\n"
     ]
    }
   ],
   "source": [
    "val_accuracy2 = []\n",
    "test_accuracy2 = []\n",
    "test_split = [0.1,0.2,0.3]\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    print(\"epoch:\", epoch+1)\n",
    "    test_split = [0.1,0.2,0.3]\n",
    "    for i in test_split:\n",
    "        print(\"test_size\", i)\n",
    "        # Spliting the data into train,test and validation in 60 , 20, 20 respectively\n",
    "        Q_train, Q_test, T_train, T_test = train_test_split(reCommonWords,data[\"Topic\"], test_size=i, random_state=0)\n",
    "        Q_train, Q_val, T_train, T_val  = train_test_split(Q_train, T_train, test_size=0.2, random_state=0)\n",
    "        ## Applying vectorizer\n",
    "        vectorizer = CountVectorizer()\n",
    "        vectorizedTrainQuestions = vectorizer.fit_transform(Q_train)\n",
    "        encodedTestQuestions = vectorizer.transform(Q_test)\n",
    "        valTestQuestions = vectorizer.transform(Q_val)\n",
    "         # Applying Logistic Regression\n",
    "        model = LogisticRegression(multi_class='ovr', solver='liblinear')\n",
    "        # Fitting the data\n",
    "        model = model.fit(vectorizedTrainQuestions,T_train)\n",
    "        # Prediction using test data\n",
    "        predicted = model.predict(encodedTestQuestions)\n",
    "        # Prediction using validation data\n",
    "        val_prediction = model.predict(valTestQuestions)\n",
    "        if(i == 0.2):\n",
    "            test_accuracy2.append(accuracy_score(predicted,T_test))\n",
    "        val_accuracy2.append(accuracy_score(val_prediction,T_val))\n",
    "        print(accuracy_score(T_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "test_size 0.1\n",
      "0.9181818181818182\n",
      "test_size 0.2\n",
      "0.8977272727272727\n",
      "test_size 0.3\n",
      "0.9272727272727272\n",
      "epoch: 2\n",
      "test_size 0.1\n",
      "0.9181818181818182\n",
      "test_size 0.2\n",
      "0.8977272727272727\n",
      "test_size 0.3\n",
      "0.9272727272727272\n",
      "epoch: 3\n",
      "test_size 0.1\n",
      "0.9181818181818182\n",
      "test_size 0.2\n",
      "0.8977272727272727\n",
      "test_size 0.3\n",
      "0.9272727272727272\n",
      "epoch: 4\n",
      "test_size 0.1\n",
      "0.9181818181818182\n",
      "test_size 0.2\n",
      "0.8977272727272727\n",
      "test_size 0.3\n",
      "0.9272727272727272\n",
      "epoch: 5\n",
      "test_size 0.1\n",
      "0.9181818181818182\n",
      "test_size 0.2\n",
      "0.8977272727272727\n",
      "test_size 0.3\n",
      "0.9272727272727272\n",
      "epoch: 6\n",
      "test_size 0.1\n",
      "0.9181818181818182\n",
      "test_size 0.2\n",
      "0.8977272727272727\n",
      "test_size 0.3\n",
      "0.9272727272727272\n",
      "epoch: 7\n",
      "test_size 0.1\n",
      "0.9181818181818182\n",
      "test_size 0.2\n",
      "0.8977272727272727\n",
      "test_size 0.3\n",
      "0.9272727272727272\n",
      "epoch: 8\n",
      "test_size 0.1\n",
      "0.9181818181818182\n",
      "test_size 0.2\n",
      "0.8977272727272727\n",
      "test_size 0.3\n",
      "0.9272727272727272\n",
      "epoch: 9\n",
      "test_size 0.1\n",
      "0.9181818181818182\n",
      "test_size 0.2\n",
      "0.8977272727272727\n",
      "test_size 0.3\n",
      "0.9272727272727272\n",
      "epoch: 10\n",
      "test_size 0.1\n",
      "0.9181818181818182\n",
      "test_size 0.2\n",
      "0.8977272727272727\n",
      "test_size 0.3\n",
      "0.9272727272727272\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import random\n",
    "epochs = 10\n",
    "test_accuracy3 = []\n",
    "val_accuracy3 = []\n",
    "train_accuracy3 = []\n",
    "for epoch in range(epochs):\n",
    "    print(\"epoch:\", epoch+1)\n",
    "    test_split = [0.1,0.2,0.3]\n",
    "    for i in test_split:\n",
    "        print(\"test_size\", i)\n",
    "        # Spliting the data into train,test and validation in 60 , 20, 20 respectively\n",
    "        Q_train, Q_test, T_train, T_test = train_test_split(reCommonWords,data[\"Topic\"] , test_size=i, random_state=0)\n",
    "        Q_train, Q_val, T_train, T_val  = train_test_split(Q_train, T_train, test_size=0.2, random_state=0)\n",
    "        ## Applying vectorizer\n",
    "        vectorizer = TfidfVectorizer(min_df=1)\n",
    "        vectorizedTrainQuestions = vectorizer.fit_transform(Q_train)\n",
    "        encodedTestQuestions = vectorizer.transform(Q_test)\n",
    "        valTestQuestions = vectorizer.transform(Q_val)\n",
    "        # Applying multinomialNB\n",
    "        mnb = MultinomialNB()\n",
    "        # Fitting the data\n",
    "        mnb.fit(vectorizedTrainQuestions,T_train)\n",
    "        # Prediction using train data\n",
    "        Tr_prediction = mnb.predict(vectorizedTrainQuestions)\n",
    "        # Prediction using test data\n",
    "        T_prediction = mnb.predict(encodedTestQuestions)\n",
    "        # Prediction using validation data\n",
    "        val_prediction = mnb.predict(valTestQuestions)\n",
    "        train_accuracy3.append(accuracy_score(Tr_prediction,T_train))\n",
    "        if(i == 0.2):\n",
    "            test_accuracy3.append(accuracy_score(T_prediction,T_test))\n",
    "        val_accuracy3.append(accuracy_score(val_prediction,T_val))\n",
    "        print(accuracy_score(T_test, T_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "test_size 0.1\n",
      "0.8954545454545455\n",
      "test_size 0.2\n",
      "0.9136363636363637\n",
      "test_size 0.3\n",
      "0.9287878787878788\n",
      "epoch: 2\n",
      "test_size 0.1\n",
      "0.8954545454545455\n",
      "test_size 0.2\n",
      "0.9136363636363637\n",
      "test_size 0.3\n",
      "0.9287878787878788\n",
      "epoch: 3\n",
      "test_size 0.1\n",
      "0.8954545454545455\n",
      "test_size 0.2\n",
      "0.9136363636363637\n",
      "test_size 0.3\n",
      "0.9287878787878788\n",
      "epoch: 4\n",
      "test_size 0.1\n",
      "0.8954545454545455\n",
      "test_size 0.2\n",
      "0.9136363636363637\n",
      "test_size 0.3\n",
      "0.9287878787878788\n",
      "epoch: 5\n",
      "test_size 0.1\n",
      "0.8954545454545455\n",
      "test_size 0.2\n",
      "0.9136363636363637\n",
      "test_size 0.3\n",
      "0.9287878787878788\n",
      "epoch: 6\n",
      "test_size 0.1\n",
      "0.8954545454545455\n",
      "test_size 0.2\n",
      "0.9136363636363637\n",
      "test_size 0.3\n",
      "0.9287878787878788\n",
      "epoch: 7\n",
      "test_size 0.1\n",
      "0.8954545454545455\n",
      "test_size 0.2\n",
      "0.9136363636363637\n",
      "test_size 0.3\n",
      "0.9287878787878788\n",
      "epoch: 8\n",
      "test_size 0.1\n",
      "0.8954545454545455\n",
      "test_size 0.2\n",
      "0.9136363636363637\n",
      "test_size 0.3\n",
      "0.9287878787878788\n",
      "epoch: 9\n",
      "test_size 0.1\n",
      "0.8954545454545455\n",
      "test_size 0.2\n",
      "0.9136363636363637\n",
      "test_size 0.3\n",
      "0.9287878787878788\n",
      "epoch: 10\n",
      "test_size 0.1\n",
      "0.8954545454545455\n",
      "test_size 0.2\n",
      "0.9136363636363637\n",
      "test_size 0.3\n",
      "0.9287878787878788\n",
      "[0.9136363636363637, 0.9136363636363637, 0.9136363636363637, 0.9136363636363637, 0.9136363636363637, 0.9136363636363637, 0.9136363636363637, 0.9136363636363637, 0.9136363636363637, 0.9136363636363637]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "test_accuracy4 = []\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "test_split = [0.1,0.2,0.3]\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    print(\"epoch:\", epoch+1)\n",
    "    test_split = [0.1,0.2,0.3]\n",
    "    for i in test_split:\n",
    "        print(\"test_size\", i)\n",
    "        # Spliting the data into train,test and validation in 60 , 20, 20 respectively\n",
    "        Q_train, Q_test, T_train, T_test = train_test_split(reCommonWords,data[\"Topic\"] , test_size=i, random_state=0)\n",
    "        Q_train, Q_val, T_train, T_val  = train_test_split(Q_train, T_train, test_size=0.2, random_state=0)\n",
    "        ## Applying vectorizer\n",
    "        vectorizer = TfidfVectorizer(min_df=1,stop_words='english')\n",
    "        vectorizedTrainQuestions = vectorizer.fit_transform(Q_train)\n",
    "        encodedTestQuestions = vectorizer.transform(Q_test)\n",
    "        # Applying Logistic Regression\n",
    "        model = LogisticRegression()\n",
    "        # Fitting the data\n",
    "        model = model.fit(vectorizedTrainQuestions,T_train)\n",
    "        # Prediction using test data\n",
    "        predicted = model.predict(encodedTestQuestions)\n",
    "        if(i == 0.2):\n",
    "            test_accuracy4.append(accuracy_score(predicted,T_test))\n",
    "        print(accuracy_score(T_test, predicted))\n",
    "print(test_accuracy4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertWV(para):\n",
    "    output = []   \n",
    "    for line in para:\n",
    "        line = line.split(\" \")\n",
    "        inn = []\n",
    "        for i in range(len(line)):\n",
    "            try:\n",
    "                x = model[line[i].lower()]\n",
    "            except:\n",
    "                x = np.zeros(300)\n",
    "            inn.append(x)\n",
    "        output.append(inn)\n",
    "    w2v = [sum(element) for element in output]\n",
    "    return w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 1\n",
      "testSize: 0.1\n",
      "0.9545454545454546\n",
      "testSize: 0.2\n",
      "0.9363636363636364\n",
      "testSize: 0.3\n",
      "0.9090909090909091\n",
      "epochs: 2\n",
      "testSize: 0.1\n",
      "0.9318181818181818\n",
      "testSize: 0.2\n",
      "0.9545454545454546\n",
      "testSize: 0.3\n",
      "0.9257575757575758\n",
      "epochs: 3\n",
      "testSize: 0.1\n",
      "0.9409090909090909\n",
      "testSize: 0.2\n",
      "0.9318181818181818\n",
      "testSize: 0.3\n",
      "0.9257575757575758\n",
      "epochs: 4\n",
      "testSize: 0.1\n",
      "0.9363636363636364\n",
      "testSize: 0.2\n",
      "0.925\n",
      "testSize: 0.3\n",
      "0.9151515151515152\n",
      "epochs: 5\n",
      "testSize: 0.1\n",
      "0.9227272727272727\n",
      "testSize: 0.2\n",
      "0.9295454545454546\n",
      "testSize: 0.3\n",
      "0.9318181818181818\n",
      "epochs: 6\n",
      "testSize: 0.1\n",
      "0.9\n",
      "testSize: 0.2\n",
      "0.9227272727272727\n",
      "testSize: 0.3\n",
      "0.9242424242424242\n",
      "epochs: 7\n",
      "testSize: 0.1\n",
      "0.9227272727272727\n",
      "testSize: 0.2\n",
      "0.9454545454545454\n",
      "testSize: 0.3\n",
      "0.9272727272727272\n",
      "epochs: 8\n",
      "testSize: 0.1\n",
      "0.9\n",
      "testSize: 0.2\n",
      "0.9318181818181818\n",
      "testSize: 0.3\n",
      "0.9272727272727272\n",
      "epochs: 9\n",
      "testSize: 0.1\n",
      "0.9318181818181818\n",
      "testSize: 0.2\n",
      "0.925\n",
      "testSize: 0.3\n",
      "0.9303030303030303\n",
      "epochs: 10\n",
      "testSize: 0.1\n",
      "0.9227272727272727\n",
      "testSize: 0.2\n",
      "0.9181818181818182\n",
      "testSize: 0.3\n",
      "0.9212121212121213\n",
      "[0.9363636363636364, 0.9545454545454546, 0.9318181818181818, 0.925, 0.9295454545454546, 0.9227272727272727, 0.9454545454545454, 0.9318181818181818, 0.925, 0.9181818181818182]\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "accuracy = []\n",
    "testSplit = [0.1,0.2,0.3]\n",
    "for epoch in range(epochs):\n",
    "    print(\"epochs:\",epoch + 1)\n",
    "    for size in testSplit:\n",
    "        print(\"testSize:\",size)\n",
    "        questionTrain, questionTest, labelTrain, labelTest =train_test_split(reCommonWords,data[\"Topic\"] , test_size = size)\n",
    "        questionTrain, questionVal, labelTrain, labelVal =train_test_split(questionTrain, labelTrain, test_size = 0.2)\n",
    "        lR = LogisticRegression()\n",
    "        lR = lR.fit (convertWV(questionTrain),labelTrain)\n",
    "        probability = lR.predict_proba(convertWV(questionTest))\n",
    "        predicted = lR.predict(convertWV(questionTest))\n",
    "        if(size == 0.2):\n",
    "            accuracy.append(accuracy_score(labelTest,predicted))\n",
    "        print(accuracy_score(labelTest,predicted))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
